{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-06T17:17:19.341699Z","iopub.execute_input":"2023-10-06T17:17:19.342353Z","iopub.status.idle":"2023-10-06T17:17:19.784157Z","shell.execute_reply.started":"2023-10-06T17:17:19.342307Z","shell.execute_reply":"2023-10-06T17:17:19.782954Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/dataindoml/massive_train.solution\n/kaggle/input/dataindoml/massive_train.data\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers torch","metadata":{"execution":{"iopub.status.busy":"2023-10-06T17:17:19.786122Z","iopub.execute_input":"2023-10-06T17:17:19.786859Z","iopub.status.idle":"2023-10-06T17:17:29.237094Z","shell.execute_reply.started":"2023-10-06T17:17:19.786825Z","shell.execute_reply":"2023-10-06T17:17:29.236004Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install accelerate -U","metadata":{"execution":{"iopub.status.busy":"2023-10-06T17:17:29.238656Z","iopub.execute_input":"2023-10-06T17:17:29.239018Z","iopub.status.idle":"2023-10-06T17:17:38.684919Z","shell.execute_reply.started":"2023-10-06T17:17:29.238966Z","shell.execute_reply":"2023-10-06T17:17:38.683804Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.22.0)\nCollecting accelerate\n  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.16.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2023.9.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.22.0\n    Uninstalling accelerate-0.22.0:\n      Successfully uninstalled accelerate-0.22.0\nSuccessfully installed accelerate-0.23.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport random\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport torch\nfrom transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer","metadata":{"execution":{"iopub.status.busy":"2023-10-06T17:17:38.687687Z","iopub.execute_input":"2023-10-06T17:17:38.688694Z","iopub.status.idle":"2023-10-06T17:17:50.814095Z","shell.execute_reply.started":"2023-10-06T17:17:38.688647Z","shell.execute_reply":"2023-10-06T17:17:50.813156Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the data from the JSON files\nwith open('/kaggle/input/dataindoml/massive_train.data', 'r') as data_file:\n    data = [json.loads(line) for line in data_file]\n\nwith open('/kaggle/input/dataindoml/massive_train.solution', 'r') as solution_file:\n    solutions = [json.loads(line) for line in solution_file]","metadata":{"execution":{"iopub.status.busy":"2023-10-06T17:17:50.815508Z","iopub.execute_input":"2023-10-06T17:17:50.816392Z","iopub.status.idle":"2023-10-06T17:18:09.773119Z","shell.execute_reply.started":"2023-10-06T17:17:50.816357Z","shell.execute_reply":"2023-10-06T17:18:09.772136Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(data[0])","metadata":{"execution":{"iopub.status.busy":"2023-10-06T17:18:09.774549Z","iopub.execute_input":"2023-10-06T17:18:09.775106Z","iopub.status.idle":"2023-10-06T17:18:09.780610Z","shell.execute_reply.started":"2023-10-06T17:18:09.775075Z","shell.execute_reply":"2023-10-06T17:18:09.779719Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"{'indoml_id': 'af-ZA|1', 'id': '1', 'locale': 'af-ZA', 'partition': 'train', 'scenario': 'alarm', 'utt': 'maak my wakker nege-uur v. m. op vrydag', 'annot_utt': 'maak my wakker [time : nege-uur v. m.] op [date : vrydag]', 'worker_id': '20', 'slot_method': [{'slot': 'time', 'method': 'translation'}, {'slot': 'date', 'method': 'translation'}], 'judgments': [{'worker_id': '40', 'intent_score': 1, 'slots_score': 1, 'grammar_score': 4, 'spelling_score': 2, 'language_identification': 'target'}, {'worker_id': '49', 'intent_score': 1, 'slots_score': 1, 'grammar_score': 4, 'spelling_score': 2, 'language_identification': 'target'}, {'worker_id': '20', 'intent_score': 1, 'slots_score': 1, 'grammar_score': 4, 'spelling_score': 2, 'language_identification': 'target'}]}\n","output_type":"stream"}]},{"cell_type":"code","source":"print(solutions[0])","metadata":{"execution":{"iopub.status.busy":"2023-10-06T17:18:09.782208Z","iopub.execute_input":"2023-10-06T17:18:09.782812Z","iopub.status.idle":"2023-10-06T17:18:09.799341Z","shell.execute_reply.started":"2023-10-06T17:18:09.782782Z","shell.execute_reply":"2023-10-06T17:18:09.798253Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"{'indoml_id': 'af-ZA|1', 'intent': 'alarm_set'}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a dictionary to map indoml_id to intents\nintent_map = {item['indoml_id']: item['intent'] for item in solutions}\n\n# Split data into train and test sets (2:1) stratified by intent\nindoml_ids = [item['indoml_id'] for item in data]\nintents = [intent_map[indoml_id] for indoml_id in indoml_ids]\n\nutt = [item['utt'] for item in data]\n\nnum_classes = len(set(intents))\nprint(\"Number of classes\")\nprint(num_classes)\n\ntrain_data, test_data, train_labels, test_labels = train_test_split(\n    utt, intents, test_size=0.33, random_state=42, stratify=intents\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-06T17:18:09.800823Z","iopub.execute_input":"2023-10-06T17:18:09.801195Z","iopub.status.idle":"2023-10-06T17:18:12.018283Z","shell.execute_reply.started":"2023-10-06T17:18:09.801158Z","shell.execute_reply":"2023-10-06T17:18:12.017248Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Number of classes\n60\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install --upgrade numpy","metadata":{"execution":{"iopub.status.busy":"2023-10-06T17:18:12.022702Z","iopub.execute_input":"2023-10-06T17:18:12.024806Z","iopub.status.idle":"2023-10-06T17:18:27.019099Z","shell.execute_reply.started":"2023-10-06T17:18:12.024772Z","shell.execute_reply":"2023-10-06T17:18:27.017837Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.23.5)\nCollecting numpy\n  Downloading numpy-1.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.5\n    Uninstalling numpy-1.23.5:\n      Successfully uninstalled numpy-1.23.5\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.0 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\nfitter 1.6.0 requires pandas<3.0.0,>=2.0.3, but you have pandas 2.0.2 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nnumba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.0 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.26.0 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ntensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.26.0 which is incompatible.\nwoodwork 0.26.0 requires numpy<1.25.0,>=1.22.0, but you have numpy 1.26.0 which is incompatible.\nydata-profiling 4.3.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.26.0 which is incompatible.\nydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.25.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the BERT model and tokenizer\n# keep `ignore_mismatched_sizes=True` so that the classification layer is randomly initialized\nmodel_name = \"cartesinus/bert-base-uncased-amazon-massive-intent\"\ntokenizer = BertTokenizer.from_pretrained(model_name)\nmodel = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_classes, ignore_mismatched_sizes=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-06T17:18:27.022661Z","iopub.execute_input":"2023-10-06T17:18:27.022928Z","iopub.status.idle":"2023-10-06T17:18:31.613341Z","shell.execute_reply.started":"2023-10-06T17:18:27.022903Z","shell.execute_reply":"2023-10-06T17:18:31.612378Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab0c3aa292124958800fff67edf8d376"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c126244224048acb3c4ef34f56c03fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/348 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b7d2275628a468dbec8a44bc4ac19ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/4.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbb74c3a941d44f680bd8d5b3b6e977c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ca02a09fd754a6490f8142f54a517d6"}},"metadata":{}}]},{"cell_type":"code","source":"# Tokenize the input data\ntrain_encodings = tokenizer(\n    train_data,\n    truncation=True,\n    padding=True,\n    max_length=32,\n    return_tensors='pt'    #return type is pytorch tensor\n)\n\ntest_encodings = tokenizer(\n    test_data,\n    truncation=True,\n    padding=True,\n    max_length=32,\n    return_tensors='pt'\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-06T17:18:31.614677Z","iopub.execute_input":"2023-10-06T17:18:31.615233Z","iopub.status.idle":"2023-10-06T17:21:04.110023Z","shell.execute_reply.started":"2023-10-06T17:18:31.615201Z","shell.execute_reply":"2023-10-06T17:21:04.109066Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Convert labels to numeric values\nlabel_map = {intent: i for i, intent in enumerate(set(train_labels))}\ntrain_labels = [label_map[label] for label in train_labels]\ntest_labels = [label_map[label] for label in test_labels]","metadata":{"execution":{"iopub.status.busy":"2023-10-06T17:21:49.537277Z","iopub.execute_input":"2023-10-06T17:21:49.537601Z","iopub.status.idle":"2023-10-06T17:21:49.804279Z","shell.execute_reply.started":"2023-10-06T17:21:49.537576Z","shell.execute_reply":"2023-10-06T17:21:49.803376Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Create PyTorch datasets\nclass IntentDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = IntentDataset(train_encodings, train_labels)\ntest_dataset = IntentDataset(test_encodings, test_labels)","metadata":{"execution":{"iopub.status.busy":"2023-10-06T17:21:55.201438Z","iopub.execute_input":"2023-10-06T17:21:55.201772Z","iopub.status.idle":"2023-10-06T17:21:55.208167Z","shell.execute_reply.started":"2023-10-06T17:21:55.201744Z","shell.execute_reply":"2023-10-06T17:21:55.207111Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Training arguments\ntraining_args = TrainingArguments(\n    output_dir='./intent_classification',\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    evaluation_strategy=\"epoch\", # use 'epoch' for evaluating every epoch\n    logging_steps=10000,\n    eval_steps=10000,\n    save_total_limit=5,\n    learning_rate=1e-4,\n    num_train_epochs=3,\n    logging_dir='./logs',\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-06T17:21:58.327485Z","iopub.execute_input":"2023-10-06T17:21:58.327830Z","iopub.status.idle":"2023-10-06T17:21:58.369251Z","shell.execute_reply.started":"2023-10-06T17:21:58.327802Z","shell.execute_reply":"2023-10-06T17:21:58.368331Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Create a trainer and train the model\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-10-06T17:22:24.885609Z","iopub.execute_input":"2023-10-06T17:22:24.885945Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.12 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231006_172619-t9w9kqmm</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/loneowaisahmad/huggingface/runs/t9w9kqmm' target=\"_blank\">rose-salad-1</a></strong> to <a href='https://wandb.ai/loneowaisahmad/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/loneowaisahmad/huggingface' target=\"_blank\">https://wandb.ai/loneowaisahmad/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/loneowaisahmad/huggingface/runs/t9w9kqmm' target=\"_blank\">https://wandb.ai/loneowaisahmad/huggingface/runs/t9w9kqmm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='21001' max='36885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [21001/36885 46:56 < 35:30, 7.46 it/s, Epoch 1.71/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.173400</td>\n      <td>1.520643</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"}]},{"cell_type":"code","source":"# Predict on the test set\nraw_predictions = trainer.predict(test_dataset)\npredicted_labels = np.argmax(raw_predictions.predictions, axis=1)\n\n# Convert labels back to original intents\npredicted_intents = [list(label_map.keys())[list(label_map.values()).index(label)] for label in predicted_labels]\n\n# Print one sample prediction\nsample_idx = random.randint(0, len(test_data) - 1)\nsample_text = test_data[sample_idx]\nsample_intent = predicted_intents[sample_idx]\n\nprint(f\"Sample Text: {sample_text}\")\nprint(f\"Predicted Intent: {sample_intent}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate accuracy, precision, recall, and F1-score\nreport = classification_report(test_labels, predicted_labels, target_names=list(label_map.keys()), output_dict=True)\n\naccuracy = report['accuracy']\nprecision = report['macro avg']['precision']\nrecall = report['macro avg']['recall']\nf1_score = report['macro avg']['f1-score']\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1_score:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}